{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>RaDeg</th>\n",
       "      <th>DecDeg</th>\n",
       "      <th>AlertMag</th>\n",
       "      <th>HistoricMag</th>\n",
       "      <th>HistoricStdDev</th>\n",
       "      <th>Class</th>\n",
       "      <th>Published</th>\n",
       "      <th>Comment</th>\n",
       "      <th>TNSid</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Class_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaia20ewl</td>\n",
       "      <td>2020-10-17 18:25:40</td>\n",
       "      <td>93.82966</td>\n",
       "      <td>-29.31926</td>\n",
       "      <td>18.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SN Ia</td>\n",
       "      <td>2020-10-21 14:09:22</td>\n",
       "      <td>confirmed SN Ia</td>\n",
       "      <td>SN2020uyg</td>\n",
       "      <td>SN Ia</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gaia20ewk</td>\n",
       "      <td>2020-10-16 23:38:06</td>\n",
       "      <td>128.63759</td>\n",
       "      <td>-1.95792</td>\n",
       "      <td>18.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SN Ia</td>\n",
       "      <td>2020-10-21 14:08:44</td>\n",
       "      <td>confirmed SN Ia</td>\n",
       "      <td>SN2020tnq</td>\n",
       "      <td>SN Ia</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaia20evz</td>\n",
       "      <td>2020-10-20 06:34:41</td>\n",
       "      <td>173.78373</td>\n",
       "      <td>22.45434</td>\n",
       "      <td>17.54</td>\n",
       "      <td>17.79</td>\n",
       "      <td>0.04</td>\n",
       "      <td>QSO</td>\n",
       "      <td>2020-10-21 13:05:45</td>\n",
       "      <td>~0.3 mag rise in known QSO</td>\n",
       "      <td>AT2020xtf</td>\n",
       "      <td>QSO</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaia20evy</td>\n",
       "      <td>2020-10-19 09:48:10</td>\n",
       "      <td>244.86595</td>\n",
       "      <td>42.51098</td>\n",
       "      <td>16.80</td>\n",
       "      <td>18.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>CV</td>\n",
       "      <td>2020-10-21 13:04:08</td>\n",
       "      <td>known CV ASASSN-14fl in 3 mag outburst</td>\n",
       "      <td>AT2020xte</td>\n",
       "      <td>CV</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaia20evx</td>\n",
       "      <td>2020-10-19 16:52:24</td>\n",
       "      <td>169.27603</td>\n",
       "      <td>20.23541</td>\n",
       "      <td>16.33</td>\n",
       "      <td>17.49</td>\n",
       "      <td>0.16</td>\n",
       "      <td>BL Lac</td>\n",
       "      <td>2020-10-21 13:03:26</td>\n",
       "      <td>known BL Lac brightens by 1 mag in 5 months</td>\n",
       "      <td>AT2020xtd</td>\n",
       "      <td>BL Lac</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name                 Date      RaDeg    DecDeg  AlertMag  HistoricMag  \\\n",
       "0  Gaia20ewl  2020-10-17 18:25:40   93.82966 -29.31926     18.38          NaN   \n",
       "1  Gaia20ewk  2020-10-16 23:38:06  128.63759  -1.95792     18.53          NaN   \n",
       "2  Gaia20evz  2020-10-20 06:34:41  173.78373  22.45434     17.54        17.79   \n",
       "3  Gaia20evy  2020-10-19 09:48:10  244.86595  42.51098     16.80        18.99   \n",
       "4  Gaia20evx  2020-10-19 16:52:24  169.27603  20.23541     16.33        17.49   \n",
       "\n",
       "   HistoricStdDev   Class            Published  \\\n",
       "0             NaN   SN Ia  2020-10-21 14:09:22   \n",
       "1             NaN   SN Ia  2020-10-21 14:08:44   \n",
       "2            0.04     QSO  2020-10-21 13:05:45   \n",
       "3            0.96      CV  2020-10-21 13:04:08   \n",
       "4            0.16  BL Lac  2020-10-21 13:03:26   \n",
       "\n",
       "                                       Comment      TNSid Feature  \\\n",
       "0                              confirmed SN Ia  SN2020uyg   SN Ia   \n",
       "1                              confirmed SN Ia  SN2020tnq   SN Ia   \n",
       "2                   ~0.3 mag rise in known QSO  AT2020xtf     QSO   \n",
       "3       known CV ASASSN-14fl in 3 mag outburst  AT2020xte      CV   \n",
       "4  known BL Lac brightens by 1 mag in 5 months  AT2020xtd  BL Lac   \n",
       "\n",
       "  Class_Comment  \n",
       "0         Class  \n",
       "1         Class  \n",
       "2         Class  \n",
       "3         Class  \n",
       "4         Class  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------\n",
    "#IMPORT THE REQUIRED LIBRARIES\n",
    "#------------------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "import timeit\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------\n",
    "#DATA LOADING AND CLEANING\n",
    "#-------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------\n",
    "\n",
    "#Downloaded on 22/10/2020 a las 9:20\n",
    "df = pd.read_csv(\"alerts22102020_920.csv\")\n",
    "\n",
    "#Unification of the names of each columns by removing unnecessary spaces and characters\n",
    "df.columns = df.columns.str.lstrip().str.replace('#', '')\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "#CLASS \n",
    "#Extraction of the different classes provided by the database\n",
    "df[\"Class\"].unique()\n",
    "class_freq=df.groupby(\"Class\").agg(frequency=(\"Class\", \"count\")).sort_values(\"frequency\", ascending=False)\n",
    "#class_freq[class_freq[\"frequency\"]>20]\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "#COMMENT\n",
    "#Unification of comments with equal meaning\n",
    "for i in range(len(df[\"Comment\"])):\n",
    "    df[\"Comment\"][i]=str(df[\"Comment\"][i]).replace(\"hostless blue transient\", \"blue hostless transient\").replace(\"hostless, blue transient\", \"blue hostless transient\")\n",
    "    df[\"Comment\"][i]=str(df[\"Comment\"][i]).replace(\"confirmed SNIa\",\"confirmed SN Ia\")\n",
    "    df[\"Comment\"][i]=str(df[\"Comment\"][i]).replace(\"Candidate SN\",\"candidate SN\")\n",
    "    df[\"Comment\"][i]=str(df[\"Comment\"][i]).replace(\"candidate CV, blue hostless transient\",\"blue hostless transient, candidate CV\")\n",
    "\n",
    "#Extraction of the different comments present in the database as well as the frequency of each one.\n",
    "com_freq=df.groupby(\"Comment\").agg(frequency=(\"Comment\", \"count\")).sort_values(\"frequency\", ascending=False)\n",
    "#com_freq[com_freq[\"frequency\"]>20]\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "#NEW COLUMN \"CLASS_COMMENT\"\n",
    "#Creation of a new column \"Class_comment\" where the class of the alert will appear as long as it exists,\n",
    "#when no class is available, this gap will be filled with the comment.\n",
    "\n",
    "clcom=[]\n",
    "feature=[]\n",
    "for i in range(df.shape[0]):\n",
    "    if df[\"Class\"][i]==\"unknown\":\n",
    "        feature.append(df[\"Comment\"][i])\n",
    "        clcom.append(\"Comment\")\n",
    "    else:\n",
    "        feature.append(df[\"Class\"][i])\n",
    "        clcom.append(\"Class\")\n",
    "df[\"Feature\"]=feature\n",
    "df[\"Class_Comment\"]=clcom\n",
    "\n",
    "#Extraction of the different \"Class_comments\" present in the database as well as the frequency of each one.\n",
    "clcom_freq=df.groupby(\"Feature\").agg(frequency=(\"Feature\", \"count\")).sort_values(\"frequency\", ascending=False)\n",
    "#clcom_freq[clcom_freq[\"frequency\"]>20]\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "#RESTRUCTURING THE DATABASE\n",
    "#Filter according to frequency\n",
    "c, n = np.unique(df[\"Feature\"], return_counts=True)\n",
    "name, num=[c[i] for i in range(len(c)) if (n[i]>50 and c[i]!=\"nan\")], [n[i] for i in range(len(n)) if (n[i]>50 and c[i]!=\"nan\")]\n",
    "#pd.DataFrame([name,num])\n",
    "\n",
    "#Construction of the dataset\n",
    "df_classifier= df[df.Feature.isin(name)]\n",
    "df_classifier = df_classifier.reset_index(drop=True)\n",
    "df_classifier.to_csv('less50.csv')\n",
    "df_classifier.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------\n",
    "#ORDER ALERT FUNCTION\n",
    "#------------------------------------------------------------------------------------\n",
    "#This function will return the position of the spectrum corresponding to the alert.\n",
    "\n",
    "def alert_detection(name):\n",
    "    \n",
    "    #Data load\n",
    "    page = requests.get('http://gsaweb.ast.cam.ac.uk/alerts/alert/'+ name).text \n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    #Extraction of the magnitude and date of the alert\n",
    "    #It is important to extract both because in certain cases the magnitude is repeated\n",
    "    \n",
    "    #Import all dl files\n",
    "    dl = soup.find_all('dl',class_=\"dl-left\")\n",
    "    gross = str(dl)\n",
    "    clean = gross.replace(\"<dd>\",\"\").replace(\"</dd>\",\"\").replace(\"<dt>\",\"\").replace(\"</dt>\",\"\")\n",
    "    divide = re.split(\"\\n\", clean)\n",
    "    search_alert_date = [re.search(\"Alerting date\", i) for i in divide]\n",
    "    search_alert_mag = [re.search(\"Alerting magnitude\", i) for i in divide]\n",
    "    #Fecha y magnitud de la alerta\n",
    "    value_alert_date = divide[np.where(search_alert_date)[0][0]+1]\n",
    "    value_alert_mag = divide[np.where(search_alert_mag)[0][0]+1]\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    #For the position of the alert we compare the values obtained with those shown in the spectra\n",
    "    #Extraction of information from the spectra\n",
    "    tr = soup.find_all('tr', class_ = \"spectrum\" )\n",
    "    #Cleaning\n",
    "    divide_tr = [re.split(\"\\n\", i.text) for i in tr]\n",
    "    #Search for the right result and save the position\n",
    "    j = 0\n",
    "    for i in range(len(divide_tr)):\n",
    "        if (divide_tr[i][1] == value_alert_date) & (divide_tr[i][3] == value_alert_mag):\n",
    "            order_alert = i\n",
    "            j+=1\n",
    "    if j>0:\n",
    "        return order_alert\n",
    "    else:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------\n",
    "#SPECTRUM EXTRACTION\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "element_url=df_classifier[\"Name\"]\n",
    "\n",
    "def extract_spectrums(data):\n",
    "    #Beginning\n",
    "    tic = timeit.default_timer()\n",
    "    #Creation of the dataframe\n",
    "    df_spectrum=pd.DataFrame()\n",
    "    #Loop over each of the \"Name\" elements\n",
    "    #df_classifier.shape[0]\n",
    "    for k in range(data.shape[0]):\n",
    "        url_page = 'http://gsaweb.ast.cam.ac.uk/alerts/alert/'+ data[\"Name\"][k]\n",
    "\n",
    "        #-------------------------------------------------------------\n",
    "        #Extraction of Var_spectra on each of the alerts\n",
    "        page = requests.get(url_page).text \n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        script = soup.find_all('script') \n",
    "        search_script=[re.search(\"var spectra\", i.text) for i in script]\n",
    "        var_spectra = script[np.where(search_script)[0][0]].text.replace(\"\\n\\tvar spectra = \", \"\").replace(\";\\n\", \"\")\n",
    "        d = json.loads(var_spectra)\n",
    "        #-------------------------------------------------------------\n",
    "\n",
    "        #Empty lists where we will keep the items\n",
    "        order=[]\n",
    "        bp=[]\n",
    "        rp=[]\n",
    "        a_d=[]\n",
    "        order_alert = alert_detection(data[\"Name\"][k])\n",
    "\n",
    "        for i in range(len(d)):\n",
    "            j=[value for value in dict(d[i]).values()]\n",
    "            if j[0] == order_alert:\n",
    "                a_d.append(\"A\")\n",
    "            else:\n",
    "                a_d.append(\"D\")\n",
    "\n",
    "            order.append(j[0])\n",
    "            bp.append(j[1])\n",
    "            rp.append(j[2])\n",
    "\n",
    "\n",
    "        spectrum= {\"id\": data[\"Name\"][k],\n",
    "            \"order\": order , \n",
    "            \"bp\": bp , \n",
    "            \"rp\": rp,\n",
    "            \"a_d\": a_d,\n",
    "            \"feature\": data[\"Feature\"][k]\n",
    "            } \n",
    "\n",
    "        #Creation of the dataframe of a given alert\n",
    "        df_element = pd.DataFrame(spectrum)\n",
    "        #Gather the dataframe\n",
    "        df_spectrum = pd.concat([df_spectrum, df_element])\n",
    "\n",
    "        #-------------------------------------------------------------\n",
    "        #Counter\n",
    "        if  k % 50 == 0:\n",
    "            print(\"Link {}\".format(k))\n",
    "        #-------------------------------------------------------------\n",
    "\n",
    "    df_spectrum = df_spectrum.reset_index(drop=True)\n",
    "    toc = timeit.default_timer()\n",
    "    print (\"Computation time = \" + str((toc - tic)) + \"s\")\n",
    "    return df_spectrum \n",
    "\n",
    "#df_spectrum = extract_spectrums(df_classifier)\n",
    "#Guardamos los datos en un csv.\n",
    "#df_spectrum.to_csv('Spectrums.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaia20eqo\n",
      "Gaia20dwa\n",
      "Gaia19fkd\n",
      "Gaia19erx\n",
      "Gaia19emu\n",
      "Gaia19ddq\n",
      "Gaia19ckq\n",
      "Gaia18cxm\n",
      "Gaia18buw\n",
      "Gaia18bto\n",
      "Gaia16adk\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "#We checked the existence of elements that do not appear in the spectral dataset\n",
    "df_spect = pd.read_csv(\"Spectrums.csv\")\n",
    "\n",
    "j=0\n",
    "for i in range(df_classifier.shape[0]):\n",
    "    if df_classifier[\"Name\"][i] not in list(df_spect[\"id\"]):\n",
    "        j+=1\n",
    "        print(df_classifier[\"Name\"][i])\n",
    "print(j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
